# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, I build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary

This dataset contains bank marketing campaigns for clients. The target was to convince the clients to make a term deposit at the bank. In this project, we try to predict whether the potential client would accept a deposit.

The best performing model was Scikit-learn pipeline, which uses logistic regression.
1. Accuracy for Scikit-learn: 0.9169
2. Accuracy for AutoML pipeline (VotingEnsemble): 0.9159

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

Dataset is here: https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv . 
For data cleaning and preparation, the function clean_data was used. A dictionary was added to convert the categorical fields to numeric values; then I one-hot encoded the data. After that, I split the data with a ratio of 85:15 using the train_test_split function. 
Algorithm I used: Logistic Regression. 

Hyperparameters include:
1. C: The inverse of the reqularization strength. 
2. max_iter: Maximum number of iterations to converge.

Configuration that defines a HyperDrive run:

  - estimator: will be called upon with sampled hyper parameters from the chosen dataset.
  - run_config: object for setting up configuration for notebook runs.
  - pipeline: pipeline object for setting up configuration for pipeline runs.

Note: We need to specify only one of the following parameters: estimator, run_config, or pipeline.
  
**What are the benefits of the parameter sampler you chose?**

RandomParameterSampling is used here instead of GridParameterSampling since the hyperparameters are randomly selected from the search space and it supports early termination of low-performance runs.

**What are the benefits of the early stopping policy you chose?**

BanditPolicy is an "aggressive" early stopping policy. 

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

In AutoML many pipelines run different algorithms and parameters in an automated way. Parameters for AutoML training:

experiment_timeout_minutes = 30

task ='classification'


## Pipeline Comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?

Although there isn't much a difference in Accuracy between the two models, AutoML shows the importance of each feature for prediction and also shows some useful metric outputs like:
  - weighted_accuracy
  - f1_score_weighted
  - precision_score_macro



## Future Work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

  - Use a different stopping policy
  - Use Gridsampling instead of RandomParameterSampling



